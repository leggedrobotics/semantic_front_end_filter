{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a28948",
   "metadata": {},
   "source": [
    "# Draw the concept graph\n",
    "Open rviz and use the rviz config `bagplay_concept.rviz`. You can launch ros core and rviz from the `robotparam_and_rviz.launch`\n",
    "\n",
    "The code loads a recorded rosbag, and pass the topics into registered callback functions. You can modify the following callbacks to alter the style of the visulization. What's more, you can choose a good period for the replay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy # for `Duration`\n",
    "import rosbag\n",
    "from semantic_front_end_filter.common import RosbagPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules for the model\n",
    "from semantic_front_end_filter.adabins.pointcloudUtils import RaycastCamera\n",
    "from semantic_front_end_filter.adabins.models import UnetAdaptiveBins\n",
    "from semantic_front_end_filter.adabins.model_io import load_checkpoint, load_param_from_path\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "from semantic_front_end_filter.Labelling.messages.imageMessage import Camera, getImageId, rgb_msg_to_image\n",
    "from semantic_front_end_filter.Labelling.messages.pointcloudMessage import rospcmsg_to_pcarray, ros_pc_msg2\n",
    "from semantic_front_end_filter.Labelling.messages.messageToVectors import msg_to_body_ang_vel, msg_to_body_lin_vel, msg_to_rotmat, msg_to_command, \\\n",
    "    msg_to_pose, msg_to_joint_positions, msg_to_joint_velocities, msg_to_joint_torques, msg_to_grav_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "rosbagpath = \"/Data/Italy_0820/Reconstruct_2022-07-18-20-34-01_0.bag\"\n",
    "player = RosbagPlayer(rosbagpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e62d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node('draw_elev_map', anonymous=False)\n",
    "player.add_publisher_of_topic(\"/alphasense_driver_ros/imu\")\n",
    "player.add_publisher_of_topic(\"/tf\", queue_size=1000)\n",
    "player.add_publisher_of_topic(\"/tf_static\")\n",
    "player.add_publisher_of_topic(\"/clock\")\n",
    "player.add_publisher_of_topic(\"/twist_mux/twist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fa680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# player._callbacks = {k:v for k,v in player._callbacks.items() if k in [\"/tf\", \"/tf_static\",\"/clock\"]}\n",
    "player.play(end_time = player.bag.get_start_time()+20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()# this is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"2022-08-29-23-51-44\"\n",
    "model_path = f\"../checkpoints/{modelname}/UnetAdaptiveBins_best.pt\"\n",
    "image_topic = \"/alphasense_driver_ros/cam4/debayered\"\n",
    "pc_topic = \"/bpearl_rear/point_cloud\"\n",
    "TF_BASE = \"base\"\n",
    "TF_MAP = \"map\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "raycastCamera = RaycastCamera(device=device) # WARN: This raycastcamera is hard coded with `tf_base_to_sensor`, however, it seems to be constant\n",
    "\n",
    "\n",
    "## Initialize model\n",
    "model_cfg = load_param_from_path(model_path)\n",
    "model_cfg[\"input_channel\"] = 4\n",
    "model = UnetAdaptiveBins.build(**model_cfg)\n",
    "\n",
    "model = load_checkpoint(model_path, model)[0]\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e20d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensor_msgs import point_cloud2\n",
    "from sensor_msgs.msg import PointCloud2, PointField\n",
    "from std_msgs.msg import Header\n",
    "from sensor_msgs.msg import Image\n",
    "from visualization_msgs.msg import Marker\n",
    "from geometry_msgs.msg import Point\n",
    "import struct\n",
    "from cv_bridge import CvBridge\n",
    "image_cv_bridge = CvBridge()\n",
    "def buildPoint(x, y, z, r, g, b, a=None):\n",
    "    if(np.array([r, g, b]).max() < 1.01):\n",
    "        r = int(r * 255.0)\n",
    "        g = int(g * 255.0)\n",
    "        b = int(b * 255.0)\n",
    "        a = 255 if a is None else int(a * 255.0)\n",
    "    else:\n",
    "        r = int(r)\n",
    "        g = int(g)\n",
    "        b = int(b)\n",
    "        a = 255 if a is None else int(a)\n",
    "    rgb = struct.unpack('I', struct.pack('BBBB', b, g, r, a))[0]\n",
    "    return [x, y, z, rgb]\n",
    "rospy.init_node('draw_elev_map', anonymous=False)\n",
    "pred_pc_pub1 = rospy.Publisher(\"pc/pred_pc/pub1\", PointCloud2, queue_size=1)\n",
    "raw_pc_pub1 = rospy.Publisher(\"pc/raw_pc/pub1\", PointCloud2, queue_size=1)\n",
    "pred_pc_pub2 = rospy.Publisher(\"pc/pred_pc/pub2\", PointCloud2, queue_size=1)\n",
    "raw_pc_pub2 = rospy.Publisher(\"pc/raw_pc/pub2\", PointCloud2, queue_size=1)\n",
    "image_pub = rospy.Publisher(\"cam_image\", Image, queue_size=1)\n",
    "marker_pub = rospy.Publisher(\"pred_raw_connection\", Marker, queue_size=1)\n",
    "\n",
    "## Configs of the line_list style\n",
    "line_list_msg = Marker()\n",
    "line_list_msg.header.frame_id = \"map\"\n",
    "line_list_msg.ns = \"raw2pred\"\n",
    "line_list_msg.action = 0\n",
    "line_list_msg.type = 5\n",
    "line_list_msg.color.a = 0.2\n",
    "line_list_msg.color.r = 0.5\n",
    "line_list_msg.color.b = 0.2\n",
    "line_list_msg.color.g = 0.2\n",
    "line_list_msg.scale.x = 0.005\n",
    "line_list_msg.points = []\n",
    "\n",
    "\n",
    "player._shared_var.update(dict(\n",
    "    pcbuffer=[],\n",
    "))\n",
    "\n",
    "def pred_and_checkerr(image, pc, pose,v):\n",
    "    \"\"\"\n",
    "    Make the prediction based on image, pointcloud and robot current pose\n",
    "    arg pose: x,y,z,rx,ry,rz,rw\n",
    "    \"\"\"\n",
    "    image = torch.Tensor(image).to(device)\n",
    "    points = torch.Tensor(pc).to(device)\n",
    "#     points_highlight = points.copy()\n",
    "    highlight_mask = (points[:,2]>pose[2]-0.2)\\\n",
    "            & (torch.sum((points[:,:2]-torch.tensor(pose[:2]).to(device))**2, axis = 1)<2**2)\n",
    "\n",
    "    points_highlight = points[highlight_mask] \n",
    "    \n",
    "    # get pc image\n",
    "    pc_img = torch.zeros_like(image[:1, ...]).to(device).float()\n",
    "    pc_img,visible,proj_point = raycastCamera.project_cloud_to_depth(\n",
    "                    pose, points, pc_img, return_detail=True)\n",
    "    pc_img_highlight = torch.zeros_like(image[:1, ...]).to(device).float()\n",
    "    pc_img_highlight = raycastCamera.project_cloud_to_depth(\n",
    "                    pose, points_highlight, pc_img_highlight)\n",
    "    # filter the points to the only visble ones\n",
    "    points = points[visible] # TODO: Decide whether should be filter the raw points\n",
    "    # get prediction\n",
    "    model_in = torch.cat([image/255., pc_img],axis=0)\n",
    "    model_in = model_in[None, ...]\n",
    "    for i, (m, s) in enumerate(zip([0.387, 0.394, 0.404, 0.120], [0.322, 0.32, 0.30,  1.17])):\n",
    "        model_in[0, i, ...] = (model_in[0, i, ...] - m)/s\n",
    "    pred = model(model_in)[0][0]\n",
    "\n",
    "    pred [(pc_img[0]==0)] = np.nan\n",
    "    pred = pred.T\n",
    "\n",
    "    # get elevation from prediction\n",
    "    highlight_mask = abs(pc_img_highlight.T.reshape(-1))>1e-9\n",
    "    \n",
    "    pred_pts = raycastCamera.project_depth_to_cloud(pose, pred)\n",
    "    pred_pts_highlight = pred_pts[highlight_mask]\n",
    "    pred_pts = pred_pts[~torch.isnan(pred_pts[:,0])]\n",
    "    # pred_pts = pred_pts[pred_pts[:,2]<pose[2]] # TODO: Decide whether this hieight mask is necessary\n",
    "    pred_points = pred_pts.detach().cpu().numpy()\n",
    "    pred_points_highlight = pred_pts_highlight.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "## Deprectaed way of getting raw points and colors\n",
    "#     raw_points = points.cpu().numpy().astype(pred_points.dtype) # float_64\n",
    "#     proj_point = proj_point.cpu().numpy()\n",
    "#     colors_raw = np.moveaxis((image.cpu().numpy())[:3,proj_point[:,1], proj_point[:,0]], 0, 1)\n",
    "\n",
    "    # Use reprojected raw_pts, otherwise the position of raw pc and pred pc are not aligned\n",
    "    pc_img[abs(pc_img)<1e-9] = np.nan\n",
    "    raw_pts = raycastCamera.project_depth_to_cloud(pose, pc_img.T)\n",
    "    raw_pts_highlight = raw_pts[highlight_mask]\n",
    "    raw_rgb = torch.vstack([(image[cnl].T).reshape(-1) for cnl in range(3)]).T\n",
    "    raw_rgb = (raw_rgb-raw_rgb.min())/(raw_rgb.max() - raw_rgb.min())\n",
    "    raw_rgb_highlight = raw_rgb[highlight_mask]\n",
    "    raw_rgb = raw_rgb[~torch.isnan(raw_pts[:,0])]\n",
    "    raw_pts = raw_pts[~torch.isnan(raw_pts[:,0])]\n",
    "    raw_points = raw_pts.cpu().numpy()\n",
    "    raw_colors = raw_rgb.cpu().numpy()\n",
    "    raw_points_highlight = raw_pts_highlight.cpu().numpy()\n",
    "    raw_colors_highlight = raw_rgb_highlight.cpu().numpy()\n",
    "    \n",
    "    \n",
    "    header = Header()\n",
    "    header.frame_id = \"map\"\n",
    "    fields = [\n",
    "        PointField('x', 0, PointField.FLOAT32, 1),\n",
    "        PointField('y', 4, PointField.FLOAT32, 1),\n",
    "        PointField('z', 8, PointField.FLOAT32, 1),\n",
    "        # PointField('rgb', 12, PointField.UINT32, 1),\n",
    "        PointField('rgba', 12, PointField.UINT32, 1),\n",
    "    ]\n",
    "    \n",
    "    colors_pred = ((pred_points[:, 2]-pred_points[:, 2].min())\n",
    "        /(pred_points[:, 2].max()-pred_points[:, 2].min()))[:,None]*np.array([[1,1,1]])\n",
    "    cloud_pred = point_cloud2.create_cloud(header, fields,\n",
    "                                [buildPoint(*p[:3], *c) for p, c in zip(pred_points, colors_pred)])\n",
    "    cloud_pred_highlight = point_cloud2.create_cloud(header, fields,\n",
    "                                [buildPoint(*p[:3], 0.,0.,0.) for p in pred_points_highlight])\n",
    "    pred_pc_pub1.publish(cloud_pred)\n",
    "    pred_pc_pub2.publish(cloud_pred_highlight)\n",
    "    \n",
    "\n",
    "    \n",
    "    cloud_raw = point_cloud2.create_cloud(header, fields,\n",
    "                                [buildPoint(*p[:3], *c) for p, c in zip(raw_points, raw_colors)])\n",
    "    cloud_raw_highlight = point_cloud2.create_cloud(header, fields,\n",
    "                                [buildPoint(*p[:3], *c) for p, c in zip(raw_points_highlight, raw_colors_highlight)])\n",
    "    \n",
    "    raw_pc_pub1.publish(cloud_raw)\n",
    "    raw_pc_pub2.publish(cloud_raw_highlight)\n",
    "    \n",
    "    line_list_msg.points = [ p\n",
    "        for pp, rp in zip(pred_points_highlight[::10], raw_points_highlight[::10])\n",
    "        for p in [Point(*pp[:3]), Point(*rp[:3])]\n",
    "    ]\n",
    "    marker_pub.publish(line_list_msg)\n",
    "    \n",
    "    image_to_show = np.moveaxis(image.cpu().numpy(), 0, 2).astype(np.uint8)\n",
    "    image_pub.publish(image_cv_bridge.cv2_to_imgmsg(image_to_show, \"bgr8\"))\n",
    "#     print(\"image_to_show\", image_to_show.shape, image_to_show.mean())\n",
    "\n",
    "def image_cb(topic, msg, t, tf_buffer, v):\n",
    "    if(not len(v[\"pcbuffer\"])): return\n",
    "\n",
    "    img = rgb_msg_to_image(msg, raycastCamera.camera.is_debayered, raycastCamera.camera.rb_swap, (\"compressed\" in topic))\n",
    "    img = np.moveaxis(img, 2, 0)\n",
    "\n",
    "    if not (tf_buffer.can_transform_core(TF_MAP, TF_BASE,  msg.header.stamp)[0]): return \n",
    "    tf = tf_buffer.lookup_transform_core(TF_MAP, TF_BASE, msg.header.stamp)\n",
    "    pose = msg_to_pose(tf)  # pose in fixed ref frame (odom or map)\n",
    "\n",
    "    pc = np.concatenate(v[\"pcbuffer\"],axis = 0)\n",
    "    pred_and_checkerr(img, pc, pose, v)\n",
    "\n",
    "    v[\"pcbuffer\"] = v[\"pcbuffer\"][-10:]\n",
    "\n",
    "player.register_callback(image_topic, image_cb)\n",
    "\n",
    "\n",
    "def pointcloud_cb(topic, msg, t, tf_buffer, v):\n",
    "    if not (tf_buffer.can_transform_core(TF_MAP, msg.header.frame_id,  msg.header.stamp)[0]): return\n",
    "    tf = tf_buffer.lookup_transform_core(TF_MAP, msg.header.frame_id,  msg.header.stamp)\n",
    "    pose = msg_to_pose(tf)\n",
    "    pc_array = rospcmsg_to_pcarray(msg, pose)\n",
    "\n",
    "    v[\"pcbuffer\"].append(pc_array[:,:3])\n",
    "player.register_callback(pc_topic, pointcloud_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "player.play(start_time= player.bag.get_start_time()+22,\n",
    "            end_time = player.bag.get_start_time()+23)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
