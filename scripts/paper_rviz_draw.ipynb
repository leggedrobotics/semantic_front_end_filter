{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a28948",
   "metadata": {},
   "source": [
    "# Draw the concept graph\n",
    "Open rviz and use the rviz config `bagplay_concept.rviz`. You can launch ros core and rviz from the `robotparam_and_rviz.launch`\n",
    "\n",
    "The code loads a recorded rosbag, and pass the topics into registered callback functions. You can modify the following callbacks to alter the style of the visulization. What's more, you can choose a good period for the replay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy # for `Duration`\n",
    "import rosbag\n",
    "from semantic_front_end_filter.common import RosbagPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules for the model\n",
    "from semantic_front_end_filter.adabins.pointcloudUtils import RaycastCamera\n",
    "from semantic_front_end_filter.adabins.models import UnetAdaptiveBins\n",
    "from semantic_front_end_filter.adabins.model_io import load_checkpoint, load_param_from_path\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "from semantic_front_end_filter.Labelling.messages.imageMessage import Camera, getImageId, rgb_msg_to_image\n",
    "from semantic_front_end_filter.Labelling.messages.pointcloudMessage import rospcmsg_to_pcarray, ros_pc_msg2\n",
    "from semantic_front_end_filter.Labelling.messages.messageToVectors import msg_to_body_ang_vel, msg_to_body_lin_vel, msg_to_rotmat, msg_to_command, \\\n",
    "    msg_to_pose, msg_to_joint_positions, msg_to_joint_velocities, msg_to_joint_torques, msg_to_grav_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "rosbagpath = \"/Data/Italy_0820/Reconstruct_2022-07-18-20-34-01_0.bag\"\n",
    "player = RosbagPlayer(rosbagpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e62d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node('draw_elev_map', anonymous=False)\n",
    "player.add_publisher_of_topic(\"/alphasense_driver_ros/imu\")\n",
    "player.add_publisher_of_topic(\"/tf\", queue_size=1000)\n",
    "player.add_publisher_of_topic(\"/tf_static\")\n",
    "player.add_publisher_of_topic(\"/clock\")\n",
    "player.add_publisher_of_topic(\"/twist_mux/twist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fa680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# player._callbacks = {k:v for k,v in player._callbacks.items() if k in [\"/tf\", \"/tf_static\",\"/clock\"]}\n",
    "player.play(end_time = player.bag.get_start_time()+20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()# this is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"2022-08-29-23-51-44\"\n",
    "model_path = f\"../checkpoints/{modelname}/UnetAdaptiveBins_best.pt\"\n",
    "image_topic = \"/alphasense_driver_ros/cam4/debayered\"\n",
    "pc_topic = \"/bpearl_rear/point_cloud\"\n",
    "TF_BASE = \"base\"\n",
    "TF_MAP = \"map\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "raycastCamera = RaycastCamera(device=device) # WARN: This raycastcamera is hard coded with `tf_base_to_sensor`, however, it seems to be constant\n",
    "\n",
    "\n",
    "## Initialize model\n",
    "model_cfg = load_param_from_path(model_path)\n",
    "model_cfg[\"input_channel\"] = 4\n",
    "model = UnetAdaptiveBins.build(**model_cfg)\n",
    "\n",
    "model = load_checkpoint(model_path, model)[0]\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e20d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensor_msgs import point_cloud2\n",
    "from sensor_msgs.msg import PointCloud2, PointField\n",
    "from std_msgs.msg import Header\n",
    "from sensor_msgs.msg import Image\n",
    "from visualization_msgs.msg import Marker\n",
    "from geometry_msgs.msg import Point\n",
    "import struct\n",
    "from cv_bridge import CvBridge\n",
    "image_cv_bridge = CvBridge()\n",
    "def buildPoint(x, y, z, r, g, b, a=None):\n",
    "    if(np.array([r, g, b]).max() < 1.01):\n",
    "        r = int(r * 255.0)\n",
    "        g = int(g * 255.0)\n",
    "        b = int(b * 255.0)\n",
    "        a = 255 if a is None else int(a * 255.0)\n",
    "    else:\n",
    "        r = int(r)\n",
    "        g = int(g)\n",
    "        b = int(b)\n",
    "        a = 255 if a is None else int(a)\n",
    "    rgb = struct.unpack('I', struct.pack('BBBB', b, g, r, a))[0]\n",
    "    return [x, y, z, rgb]\n",
    "rospy.init_node('draw_elev_map', anonymous=False)\n",
    "pred_pc_pub1 = rospy.Publisher(\"pc/pred_pc/pub1\", PointCloud2, queue_size=1)\n",
    "raw_pc_pub1 = rospy.Publisher(\"pc/raw_pc/pub1\", PointCloud2, queue_size=1)\n",
    "pred_pc_pub2 = rospy.Publisher(\"pc/pred_pc/pub2\", PointCloud2, queue_size=1)\n",
    "raw_pc_pub2 = rospy.Publisher(\"pc/raw_pc/pub2\", PointCloud2, queue_size=1)\n",
    "image_pub = rospy.Publisher(\"cam_image\", Image, queue_size=1)\n",
    "marker_pub = rospy.Publisher(\"pred_raw_connection\", Marker, queue_size=1)\n",
    "\n",
    "## Configs of the line_list style\n",
    "line_list_msg = Marker()\n",
    "line_list_msg.header.frame_id = \"map\"\n",
    "line_list_msg.ns = \"raw2pred\"\n",
    "line_list_msg.action = 0\n",
    "line_list_msg.type = 5\n",
    "line_list_msg.color.a = 0.2\n",
    "line_list_msg.color.r = 0.5\n",
    "line_list_msg.color.b = 0.2\n",
    "line_list_msg.color.g = 0.2\n",
    "line_list_msg.scale.x = 0.005\n",
    "line_list_msg.points = []\n",
    "\n",
    "\n",
    "player._shared_var.update(dict(\n",
    "    pcbuffer=[],\n",
    "))\n",
    "\n",
    "def pred_and_checkerr(image, pc, pose,v):\n",
    "    \"\"\"\n",
    "    Make the prediction based on image, pointcloud and robot current pose\n",
    "    arg pose: x,y,z,rx,ry,rz,rw\n",
    "    \"\"\"\n",
    "    image = torch.Tensor(image).to(device)\n",
    "    points = torch.Tensor(pc).to(device)\n",
    "#     points_highlight = points.copy()\n",
    "    highlight_mask = (points[:,2]>pose[2]-0.2)\\\n",
    "            & (torch.sum((points[:,:2]-torch.tensor(pose[:2]).to(device))**2, axis = 1)<2**2)\n",
    "\n",
    "    points_highlight = points[highlight_mask] \n",
    "    \n",
    "    # get pc image\n",
    "    pc_img = torch.zeros_like(image[:1, ...]).to(device).float()\n",
    "    pc_img,visible,proj_point = raycastCamera.project_cloud_to_depth(\n",
    "                    pose, points, pc_img, return_detail=True)\n",
    "    pc_img_highlight = torch.zeros_like(image[:1, ...]).to(device).float()\n",
    "    pc_img_highlight = raycastCamera.project_cloud_to_depth(\n",
    "                    pose, points_highlight, pc_img_highlight)\n",
    "    # filter the points to the only visble ones\n",
    "    points = points[visible] # TODO: Decide whether should be filter the raw points\n",
    "    # get prediction\n",
    "    model_in = torch.cat([image/255., pc_img],axis=0)\n",
    "    model_in = model_in[None, ...]\n",
    "    for i, (m, s) in enumerate(zip([0.387, 0.394, 0.404, 0.120], [0.322, 0.32, 0.30,  1.17])):\n",
    "        model_in[0, i, ...] = (model_in[0, i, ...] - m)/s\n",
    "    pred = model(model_in)[0][0]\n",
    "\n",
    "    pred [(pc_img[0]==0)] = np.nan\n",
    "    pred = pred.T\n",
    "\n",
    "    # get elevation from prediction\n",
    "    highlight_mask = abs(pc_img_highlight.T.reshape(-1))>1e-9\n",
    "    \n",
    "    pred_pts = raycastCamera.project_depth_to_cloud(pose, pred)\n",
    "    pred_pts_highlight = pred_pts[highlight_mask]\n",
    "    pred_pts = pred_pts[~torch.isnan(pred_pts[:,0])]\n",
    "    # pred_pts = pred_pts[pred_pts[:,2]<pose[2]] # TODO: Decide whether this hieight mask is necessary\n",
    "    pred_points = pred_pts.detach().cpu().numpy()\n",
    "    pred_points_highlight = pred_pts_highlight.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "## Deprectaed way of getting raw points and colors\n",
    "#     raw_points = points.cpu().numpy().astype(pred_points.dtype) # float_64\n",
    "#     proj_point = proj_point.cpu().numpy()\n",
    "#     colors_raw = np.moveaxis((image.cpu().numpy())[:3,proj_point[:,1], proj_point[:,0]], 0, 1)\n",
    "\n",
    "    # Use reprojected raw_pts, otherwise the position of raw pc and pred pc are not aligned\n",
    "    pc_img[abs(pc_img)<1e-9] = np.nan\n",
    "    raw_pts = raycastCamera.project_depth_to_cloud(pose, pc_img.T)\n",
    "    raw_pts_highlight = raw_pts[highlight_mask]\n",
    "    raw_rgb = torch.vstack([(image[cnl].T).reshape(-1) for cnl in range(3)]).T\n",
    "    raw_rgb = (raw_rgb-raw_rgb.min())/(raw_rgb.max() - raw_rgb.min())\n",
    "    raw_rgb_highlight = raw_rgb[highlight_mask]\n",
    "    raw_rgb = raw_rgb[~torch.isnan(raw_pts[:,0])]\n",
    "    raw_pts = raw_pts[~torch.isnan(raw_pts[:,0])]\n",
    "    raw_points = raw_pts.cpu().numpy()\n",
    "    raw_colors = raw_rgb.cpu().numpy()\n",
    "    raw_points_highlight = raw_pts_highlight.cpu().numpy()\n",
    "    raw_colors_highlight = raw_rgb_highlight.cpu().numpy()\n",
    "    \n",
    "    \n",
    "    header = Header()\n",
    "    header.frame_id = \"map\"\n",
    "    fields = [\n",
    "        PointField('x', 0, PointField.FLOAT32, 1),\n",
    "        PointField('y', 4, PointField.FLOAT32, 1),\n",
    "        PointField('z', 8, PointField.FLOAT32, 1),\n",
    "        # PointField('rgb', 12, PointField.UINT32, 1),\n",
    "        PointField('rgba', 12, PointField.UINT32, 1),\n",
    "    ]\n",
    "    \n",
    "    colors_pred = ((pred_points[:, 2]-pred_points[:, 2].min())\n",
    "        /(pred_points[:, 2].max()-pred_points[:, 2].min()))[:,None]*np.array([[1,1,1]])\n",
    "    cloud_pred = point_cloud2.create_cloud(header, fields,\n",
    "                                [buildPoint(*p[:3], *c) for p, c in zip(pred_points, colors_pred)])\n",
    "    cloud_pred_highlight = point_cloud2.create_cloud(header, fields,\n",
    "                                [buildPoint(*p[:3], 0.,0.,0.) for p in pred_points_highlight])\n",
    "    pred_pc_pub1.publish(cloud_pred)\n",
    "    pred_pc_pub2.publish(cloud_pred_highlight)\n",
    "    \n",
    "\n",
    "    \n",
    "    cloud_raw = point_cloud2.create_cloud(header, fields,\n",
    "                                [buildPoint(*p[:3], *c) for p, c in zip(raw_points, raw_colors)])\n",
    "    cloud_raw_highlight = point_cloud2.create_cloud(header, fields,\n",
    "                                [buildPoint(*p[:3], *c) for p, c in zip(raw_points_highlight, raw_colors_highlight)])\n",
    "    \n",
    "    raw_pc_pub1.publish(cloud_raw)\n",
    "    raw_pc_pub2.publish(cloud_raw_highlight)\n",
    "    \n",
    "    line_list_msg.points = [ p\n",
    "        for pp, rp in zip(pred_points_highlight[::10], raw_points_highlight[::10])\n",
    "        for p in [Point(*pp[:3]), Point(*rp[:3])]\n",
    "    ]\n",
    "    marker_pub.publish(line_list_msg)\n",
    "    \n",
    "    image_to_show = np.moveaxis(image.cpu().numpy(), 0, 2).astype(np.uint8)\n",
    "    image_pub.publish(image_cv_bridge.cv2_to_imgmsg(image_to_show, \"bgr8\"))\n",
    "#     print(\"image_to_show\", image_to_show.shape, image_to_show.mean())\n",
    "\n",
    "def image_cb(topic, msg, t, tf_buffer, v):\n",
    "    if(not len(v[\"pcbuffer\"])): return\n",
    "\n",
    "    img = rgb_msg_to_image(msg, raycastCamera.camera.is_debayered, raycastCamera.camera.rb_swap, (\"compressed\" in topic))\n",
    "    img = np.moveaxis(img, 2, 0)\n",
    "\n",
    "    if not (tf_buffer.can_transform_core(TF_MAP, TF_BASE,  msg.header.stamp)[0]): return \n",
    "    tf = tf_buffer.lookup_transform_core(TF_MAP, TF_BASE, msg.header.stamp)\n",
    "    pose = msg_to_pose(tf)  # pose in fixed ref frame (odom or map)\n",
    "\n",
    "    pc = np.concatenate(v[\"pcbuffer\"],axis = 0)\n",
    "    pred_and_checkerr(img, pc, pose, v)\n",
    "\n",
    "    v[\"pcbuffer\"] = v[\"pcbuffer\"][-10:]\n",
    "\n",
    "player.register_callback(image_topic, image_cb)\n",
    "\n",
    "\n",
    "def pointcloud_cb(topic, msg, t, tf_buffer, v):\n",
    "    if not (tf_buffer.can_transform_core(TF_MAP, msg.header.frame_id,  msg.header.stamp)[0]): return\n",
    "    tf = tf_buffer.lookup_transform_core(TF_MAP, msg.header.frame_id,  msg.header.stamp)\n",
    "    pose = msg_to_pose(tf)\n",
    "    pc_array = rospcmsg_to_pcarray(msg, pose)\n",
    "\n",
    "    v[\"pcbuffer\"].append(pc_array[:,:3])\n",
    "player.register_callback(pc_topic, pointcloud_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "player.play(start_time= player.bag.get_start_time()+22,\n",
    "            end_time = player.bag.get_start_time()+23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29479a5",
   "metadata": {},
   "source": [
    "# Draw the foot holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "304b6160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is loaded successfully.\n",
      "Extracting Contact points ......\n",
      "Extracting Contact points ......\n",
      "Extracting Contact points ......\n",
      "Extracting Contact points ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenyu/projects/kpconv/semantic_front_end_filter/semantic_front_end_filter/Labelling/GroundfromTrajs.py:175: RuntimeWarning: invalid value encountered in true_divide\n",
      "  GroundArray = np.true_divide(GroundArray, CountContactArray)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Contact points ......\n",
      "Extracting Contact points ......\n",
      "Extracting Contact points ......\n",
      "Extracting Contact points ......\n"
     ]
    }
   ],
   "source": [
    "import rospy \n",
    "import numpy as np\n",
    "from semantic_front_end_filter.Labelling.GroundfromTrajs import GFT\n",
    "from visualization_msgs.msg import Marker, MarkerArray\n",
    "from geometry_msgs.msg import Point\n",
    "\n",
    "foottrajpath = \"/Data/Italy_0820/FeetTrajs.msgpack\"\n",
    "\n",
    "gft = GFT(FeetTrajsFile = foottrajpath, InitializeGP=False)\n",
    "foot_holds = {k : np.array(gft.getContactPoints(v)[0]) for k,v in gft.FeetTrajs.items()} # A dict of the contact points of each foot\n",
    "foot_holds_array = np.vstack(list(foot_holds.values()))\n",
    "# rosbagpath = \"/Data/Italy_0820/Reconstruct_2022-07-18-20-34-01_0.bag\"\n",
    "rospy.init_node('draw_elev_map', anonymous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c476c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_pub = rospy.Publisher(\"labeling/footholds\", Marker, queue_size=1)\n",
    "\n",
    "line_list_msg = Marker()\n",
    "line_list_msg.header.frame_id = \"map\"\n",
    "line_list_msg.ns = \"footholds\"\n",
    "line_list_msg.action = 0\n",
    "line_list_msg.type = Marker.SPHERE_LIST\n",
    "line_list_msg.color.a = 1\n",
    "line_list_msg.color.r = 0.1\n",
    "line_list_msg.color.b = 0.5\n",
    "line_list_msg.color.g = 0.2\n",
    "line_list_msg.scale.x = 0.15\n",
    "line_list_msg.points = []\n",
    "\n",
    "line_list_msg.points = [Point(*p[:3]) for p in foot_holds_array]\n",
    "\n",
    "marker_pub.publish(line_list_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "271aa4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_pub = rospy.Publisher(\"labeling/convenientaxis\", MarkerArray, queue_size=1)\n",
    "marr = MarkerArray()\n",
    "marr.markers = [\n",
    "    Marker(\n",
    "        header = Header(frame_id = \"map\"),\n",
    "        ns = \"axis\",\n",
    "        color = type(Marker().color)(\n",
    "            0,0,0,1\n",
    "        ),\n",
    "        scale = type(Marker().scale)(\n",
    "            8, 0.1, 0.1\n",
    "        ),\n",
    "        pose = Pose(\n",
    "            position = Point(-16, 38, -8)\n",
    "        ),\n",
    "        id = i\n",
    "        \n",
    "    )\n",
    "    for i in range(3)\n",
    "]\n",
    "marr.markers[0].type = Marker.ARROW\n",
    "marr.markers[1].type = Marker.ARROW\n",
    "marr.markers[2].type = Marker.ARROW\n",
    "\n",
    "\n",
    "marr.markers[0].pose.orientation = Quaternion(0,0,0,1)\n",
    "marr.markers[1].pose.orientation = Quaternion(0,0,1/np.sqrt(2), -1/np.sqrt(2))\n",
    "marr.markers[2].pose.orientation = Quaternion(0,-1/np.sqrt(2), 0, 1/np.sqrt(2))\n",
    "axis_pub.publish(marr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98ed88",
   "metadata": {},
   "source": [
    "### Draw the reconstructed surface with gridmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d559ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ground dict, y real range:  [-3.295388865615678, 105.15809558634709] x real range:  [-108.38099452324194, 3.711307624349044]\n"
     ]
    }
   ],
   "source": [
    "from grid_map_msgs.msg import GridMap, GridMapInfo\n",
    "from geometry_msgs.msg import Pose, Quaternion\n",
    "from std_msgs.msg import Header, Float32MultiArray, MultiArrayLayout, MultiArrayDimension\n",
    "import msgpack\n",
    "import msgpack_numpy as m\n",
    "m.patch()\n",
    "\n",
    "groundmappath = \"/Data/Italy_0820/GroundMap.msgpack\"\n",
    "with open(groundmappath, \"rb\") as data_file:\n",
    "    data = data_file.read()\n",
    "    ground_dict = msgpack.unpackb(data)\n",
    "    print(\"load ground dict, y real range: \",ground_dict[\"yRealRange\"], \n",
    "                            \"x real range: \", ground_dict[\"xRealRange\"])\n",
    "    ground_dict = ground_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gp_surface_pub = rospy.Publisher(\"labeling/grid_map\", GridMap, queue_size=1);\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ffa509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['res', 'xNormal', 'yNormal', 'xRealRange', 'yRealRange', 'meanHeight', 'GroundArray', 'GPMap', 'Confidence'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33d9b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpmap = np.array(ground_dict[\"GPMap\"])\n",
    "gpmap = gpmap[::-1, ::-1]\n",
    "gpmap = gpmap.T\n",
    "\n",
    "gpmapmsg = GridMap(\n",
    "    info = GridMapInfo(\n",
    "        header= Header(frame_id=\"map\"),\n",
    "        resolution = ground_dict[\"res\"],\n",
    "        length_x = ground_dict[\"res\"] * gpmap.shape[1],\n",
    "        length_y = ground_dict[\"res\"] * gpmap.shape[0],\n",
    "        pose = Pose(\n",
    "#             position = Point(\n",
    "#                 ground_dict[\"xRealRange\"][1] - ground_dict[\"res\"] * gpmap.shape[0]/2,\n",
    "#                 ground_dict[\"yRealRange\"][1] - ground_dict[\"res\"] * gpmap.shape[1]/2,0),\n",
    "            position = Point(\n",
    "                (gpmap.shape[1]/2+ground_dict[\"xNormal\"])*ground_dict[\"res\"],\n",
    "                (gpmap.shape[0]/2+ground_dict[\"yNormal\"])*ground_dict[\"res\"],0),\n",
    "            orientation = Quaternion(x=0,y=0,z=0,w=1)\n",
    "        )),\n",
    "    layers = [\"elevation\"],\n",
    "    basic_layers = [\"elevation\"],\n",
    "    data = [\n",
    "        Float32MultiArray(\n",
    "            layout = MultiArrayLayout(\n",
    "                dim = [\n",
    "                    MultiArrayDimension(\n",
    "                        label= [\"column_index\", \"row_index\"][i],\n",
    "                        size = d,\n",
    "                        stride = np.prod( gpmap.shape[i:])\n",
    "                    )for i,d in enumerate(gpmap.shape)\n",
    "                ]\n",
    "            ),\n",
    "            data = gpmap.reshape(-1).tolist()\n",
    "            \n",
    "        )\n",
    "    ]\n",
    ")\n",
    "gp_surface_pub.publish(gpmapmsg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06caa800",
   "metadata": {},
   "source": [
    "#### Color conversion in gridmap\n",
    "\n",
    "grid_map use a float number to represent the rgb color of the map. The conversion [code](http://docs.ros.org/en/jade/api/grid_map_core/html/GridMapMath_8cpp_source.html) defns the function\n",
    "\n",
    "```c++\n",
    "bool colorVectorToValue(const Eigen::Vector3i& colorVector, unsigned long& colorValue)\n",
    "{\n",
    "  colorValue = ((int)colorVector(0)) << 16 | ((int)colorVector(1)) << 8 | ((int)colorVector(2));\n",
    "  return true;\n",
    "}\n",
    "```\n",
    "\n",
    "The way to define color should be \n",
    "```python\n",
    "color = np.array([10*2**16 + 200*2**8 + 123],dtype = np.uint32)\n",
    "color.view(np.float32)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
